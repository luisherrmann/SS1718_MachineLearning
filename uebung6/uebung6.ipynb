{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Mustererkennung und Machine Learning</h1>\n",
    "\n",
    "<h3> Wintersemester 2017/2018, 6th Exercise Sheet</h3>\n",
    "<h4>Konstantin Jaehne, Luis Herrmann; Dozent: Ra√∫l Rojas</h4>\n",
    "\n",
    "<hr style='height:1px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we read in the data required for training and testing. The data samples are contain five features and the flower name as class identifier, where the name can take 3 values. We read the data line by line from file, separating into 3 different lists according to class identifier. Then, for each list, we perform a random permutation of the element order and select 80% of the data samples for training, 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folderpath = '../'\n",
    "filename = 'iris.data'\n",
    "data = pd.read_csv(folderpath+filename, header=None).as_matrix()\n",
    "data_isetosa = []\n",
    "data_iversicolor = []\n",
    "data_ivirginica = []\n",
    "for sample in data:\n",
    "    if(sample[4] == 'Iris-setosa'):\n",
    "        data_isetosa.append(np.insert(np.array(sample[0:4], dtype=float),0,1))\n",
    "    elif(sample[4] == 'Iris-versicolor'):\n",
    "        data_iversicolor.append(np.insert(np.array(sample[0:4], dtype=float),0,1))\n",
    "    elif(sample[4] == 'Iris-virginica'):\n",
    "        data_ivirginica.append(np.insert(np.array(sample[0:4], dtype=float),0,1))\n",
    "\n",
    "rdindices = rd.sample(range(len(data_isetosa)), len(data_isetosa))\n",
    "setosa_train = np.vstack(data_isetosa)[rdindices[:int(0.8*len(data_isetosa))]]\n",
    "setosa_test = np.vstack(data_isetosa)[rdindices[int(0.8*len(data_isetosa)):]]\n",
    "\n",
    "rdindices = rd.sample(range(len(data_iversicolor)), len(data_iversicolor))\n",
    "versicolor_train = np.vstack(data_iversicolor)[rdindices[:int(0.8*len(data_isetosa))]]\n",
    "versicolor_test = np.vstack(data_iversicolor)[rdindices[int(0.8*len(data_isetosa)):]]\n",
    "\n",
    "rdindices = rd.sample(range(len(data_ivirginica)), len(data_ivirginica))\n",
    "virginica_train = np.vstack(data_ivirginica)[rdindices[:int(0.8*len(data_isetosa))]]\n",
    "virginica_test = np.vstack(data_ivirginica)[rdindices[int(0.8*len(data_isetosa)):]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a binary perceptron that works as specified in the lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPerceptron:\n",
    "    def __init__(self, data=None, labels=None, itlimit=40, keepbest=False, metric=0):\n",
    "        \"\"\"\n",
    "        data:\n",
    "            Type: List/Tuple\n",
    "            A list/tuple (l1,l2), where l1 and l2 are lists containing vectors assigned to class 1 and 2, respectively.\n",
    "        labels (optinal):\n",
    "            Type: List/Tuple\n",
    "            A list/tuple (i1,i2) of two printable identifiers associated with each class\n",
    "        itlimit (optional):\n",
    "            Type: Integer\n",
    "            Maximum number of iterations, before training is forcefully terminated.\n",
    "        keepbest (optional):\n",
    "            Type: Boolean\n",
    "            If specified, during training, the algorithm will store the best perceptron vector after each iteration and\n",
    "            once training is complete, keep the best perceptron in terms of correctly classiifed training samples.\n",
    "        metric (optional):\n",
    "            Type: Integer\n",
    "            If specified, will determine the metric to be used for determining what perceptron is best.\n",
    "            0: Highest number of correct classifications\n",
    "            1: Smallest total angle sum\n",
    "        \"\"\"\n",
    "        if(len(labels) == 2):\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            raise Exception('You must provide exactly two labels!')\n",
    "        if(len(data) != 2):\n",
    "            raise Exception('Data does not follow specified format!')\n",
    "        if(len(data[0]) == 0 or len(data[1]) == 0):\n",
    "            raise Exception('Data lists must contain at least one sample!')\n",
    "        if(not(data is None)):\n",
    "            self.train(data, itlimit=itlimit, keepbest=keepbest)\n",
    "            \n",
    "    def train(self, data, itlimit=40, keepbest=False, metric=0):\n",
    "        def terminationCheck():\n",
    "            v = np.dot(self.w, self.PN.transpose())\n",
    "            return(all(v[:self.Plen] >= 0) and all(v[self.Plen:] < 0))\n",
    "        def updateBest():\n",
    "            if(metric == 0):\n",
    "            #The vector is best when the total sum of angles becomes minimal\n",
    "                if(np.sum(np.dot(self.w, self.PN.transpose())) < np.sum(np.dot(self.w_best, self.PN.transpose()))):\n",
    "                    self.w_best = self.w\n",
    "            elif(metric == 1):\n",
    "            #The perceptron is better when the number of correct classifications is higher:\n",
    "                v = np.dot(self.w, self.PN.transpose())\n",
    "                v_best = np.dot(self.w_best, self.PN.transpose())\n",
    "                if(sum(v[:self.Plen]) >= 0) + sum(v[self.Plen:] < 0) > sum(v_best[:self.Plen] >= 0) + sum(v[self.Plen:]< 0):\n",
    "                    self.w_best = self.w\n",
    "        \n",
    "        self.Plen = len(data[0])\n",
    "        self.Nlen = len(data[1])\n",
    "        self.PN = np.vstack([data[0], data[1]])\n",
    "        self.PN = self.PN / np.sum(self.PN, axis=1)[:,np.newaxis]\n",
    "        self.w = np.random.rand(len(self.PN[0]))\n",
    "        if(keepbest):\n",
    "            self.w_best = self.w\n",
    "        t = 0\n",
    "        while(t < itlimit):\n",
    "            selectionInt = rd.randint(0, len(self.PN)-1)\n",
    "            xw = np.dot(self.PN[selectionInt], self.w)\n",
    "            if(selectionInt < self.Plen):\n",
    "                if(xw < 0):\n",
    "                    self.w += self.PN[selectionInt]\n",
    "                    t += 1\n",
    "                    if(keepbest):\n",
    "                        updateBest()\n",
    "                    sys.stdout.write(str(t) + ' iterations.\\r')\n",
    "                else:\n",
    "                    if(terminationCheck()):\n",
    "                        break\n",
    "            else:\n",
    "                if(xw >= 0):\n",
    "                    self.w -= self.PN[selectionInt]\n",
    "                    t += 1\n",
    "                    if(keepbest):\n",
    "                        updateBest()\n",
    "                    sys.stdout.write(str(t) + ' iterations.\\r')\n",
    "                else:\n",
    "                    if(terminationCheck()):\n",
    "                        break\n",
    "        \n",
    "        if(keepbest):\n",
    "               self.w = self.w_best\n",
    "        sys.stdout.write('\\nTraining complete!\\n')\n",
    "                    \n",
    "    def classify(self, x):\n",
    "        return(self.labels[int(np.dot(self.w,x) < 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations.\r",
      "2 iterations.\r",
      "3 iterations.\r",
      "4 iterations.\r",
      "5 iterations.\r",
      "6 iterations.\r",
      "7 iterations.\r",
      "8 iterations.\r",
      "9 iterations.\r",
      "10 iterations.\r",
      "11 iterations.\r",
      "12 iterations.\r\n",
      "Training complete!\n",
      "1 iterations.\r",
      "2 iterations.\r",
      "3 iterations.\r",
      "4 iterations.\r\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "C_setosa_versicolor = BinaryPerceptron([setosa_train, versicolor_train], labels = ('Iris-setosa','Iris-versicolor'))\n",
    "C_setosa_virginica = BinaryPerceptron([setosa_train, virginica_train] ,labels= ('Iris-setosa', 'Iris-virginica'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def runtest(C, data_Class0, data_Class1):\n",
    "    confusionMat = np.zeros([2, 2], dtype=int)\n",
    "    for sample in data_Class0:\n",
    "        confusionMat[0, int(C.classify(sample) != C.labels[0])] += 1\n",
    "    for sample in data_Class1:\n",
    "        confusionMat[1, int(C.classify(sample) == C.labels[1])] += 1\n",
    "    print('-The confusion matrix is given by:')\n",
    "    html = pd.DataFrame(confusionMat,index=C.labels, columns=C.labels).to_html()\n",
    "    display(HTML(html))\n",
    "    print('-The error rate is: ' + str(1-sum(np.diag(confusionMat))/(len(data_Class0) + len(data_Class1))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The confusion matrix is given by:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The error rate is: 0.0\n",
      "\n",
      "-The confusion matrix is given by:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The error rate is: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtest(C_setosa_versicolor, setosa_test, versicolor_test)\n",
    "runtest(C_setosa_virginica, setosa_test, virginica_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accomplish the second exercise, we already expanded the BinaryPerceptron class definition. Note that since the data is non-separable, the algorithm will not converge and setting an iteration limit is thus obligatory. Furthermore, note that one has to set considerably higher iteration numbers before finding a perceptron vector that separates the data well enough. Using a limit of 900 will rarely yield results with error rates lower that 0.3, sometimes finding error rates as low as 0.0, but this depends on the initial data separation and on the inital random perceptron guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 iterations.\n",
      "Training complete!\n",
      "-The confusion matrix is given by:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The error rate is: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_versicolor_virginica = BinaryPerceptron([versicolor_train, virginica_train], ('Iris-versicolor','Iris-virginica'), 900, True)\n",
    "runtest(C_versicolor_virginica, versicolor_test, virginica_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further observation, for this data set, whether we use lowest total angle sum or highest number of correct classifications did not appear to have any effect on the quality of classification. Here an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 iterations.\n",
      "Training complete!\n",
      "-The confusion matrix is given by:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-The error rate is: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_versicolor_virginica.train([versicolor_train, virginica_train], 900, True, 1)\n",
    "runtest(C_versicolor_virginica, versicolor_test, virginica_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Root)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
